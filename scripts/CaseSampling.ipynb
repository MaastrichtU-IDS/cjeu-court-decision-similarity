{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EUR-LEX Case Sampling Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract: \n",
    "#### This notebook samples cases for our study from the three chosen topics: Public Health, Data Protection & Social Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Find all case identifiers for cases concerning the three topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Public Health cases found: 181\n",
      "# of Social Policy cases found: 707\n",
      "# of Data Protection cases found: 42\n"
     ]
    }
   ],
   "source": [
    "# library for reading and writing CSV files\n",
    "import csv\n",
    "\n",
    "# Initialise variables to store case identifiers (CELEX numbers) for the three topics\n",
    "publichealth = []\n",
    "socialpolicy = []\n",
    "dataprotection = []\n",
    "\n",
    "# Find and store all case identifiers for the three topics\n",
    "with open('../inputdata/all_cases_subjects.csv', newline='') as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in csvreader:\n",
    "        if (\"health\" in row[1].lower()):\n",
    "            publichealth.append(row[0])\n",
    "        if (\"social policy\" in row[1].lower()):\n",
    "            socialpolicy.append(row[0])\n",
    "        if (\"data\" in row[1].lower()):\n",
    "            dataprotection.append(row[0])\n",
    "            \n",
    "# Remove any duplicates\n",
    "publichealth = list(set(publichealth))\n",
    "socialpolicy = list(set(socialpolicy))\n",
    "dataprotection = list(set(dataprotection))\n",
    "\n",
    "# Print the number of cases found in each topic \n",
    "print(\"# of Public Health cases found:\",len(publichealth))\n",
    "print(\"# of Social Policy cases found:\",len(socialpolicy))\n",
    "print(\"# of Data Protection cases found:\",len(dataprotection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Identify all case citations that are relevant for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas Python library for manipulation and processing of tabular data\n",
    "import pandas as pd\n",
    "\n",
    "# Import (read) the file containing the citations for all extracted cases from EUR-LEX\n",
    "citationsdata = pd.read_csv(\"../inputdata/all_cases_citations.csv\") \n",
    "# Retain only those citations that involve cases in our chosen topics:\n",
    "# 1. Public Health\n",
    "publichealthcitations = citationsdata[citationsdata['target'].isin(publichealth)]\n",
    "#print(len(publichealthcitations['target'].unique()))\n",
    "# 2. Social Policy\n",
    "socialpolicycitations = citationsdata[citationsdata['target'].isin(socialpolicy)]\n",
    "#print(len(socialpolicycitations['target'].unique()))\n",
    "# 3. Data Protection\n",
    "dataprotectioncitations = citationsdata[citationsdata['target'].isin(dataprotection)]\n",
    "#print(len(dataprotectioncitations['target'].unique()))\n",
    "\n",
    "#print(dataprotectioncitations.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Identify uncited cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I.e. cases from our original set which don't appear in 'citations.csv' (they are never cited). These uncited cases will be taken into account later on for sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify uncited cases\n",
    "def get_uncited_cases(allcases, citedcases):\n",
    "    return allcases.difference(citedcases)\n",
    "\n",
    "# 1. Public Health\n",
    "uncited_publichealth_cases = get_uncited_cases(set(publichealth), set(publichealthcitations['target'].unique()))\n",
    "#print(len(list(uncited_publichealth_cases)))\n",
    "# 2. Social Policy\n",
    "uncited_socialpolicy_cases = get_uncited_cases(set(socialpolicy), set(socialpolicycitations['target'].unique()))\n",
    "#print(len(list(uncited_socialpolicy_cases)))\n",
    "# 3 Data Protection\n",
    "uncited_dataprotection_cases = get_uncited_cases(set(dataprotection), set(dataprotectioncitations['target'].unique()))\n",
    "#print(len(list(uncited_dataprotection_cases)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Add the uncited cases into the case citations dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sort and return a frame of case identifiers sorted by their number of citations - descending order\n",
    "def get_descending_sorted_frame_of_citations(cases_dataframe):\n",
    "    return cases_dataframe.groupby('target')['source'].count().reset_index(name='citations').sort_values('citations',ascending=False)\n",
    "\n",
    "# Apply the above function to the citation frames for each topic\n",
    "publichealth_citations_sorted_df = get_descending_sorted_frame_of_citations(publichealthcitations)\n",
    "socialpolicy_citations_sorted_df = get_descending_sorted_frame_of_citations(socialpolicycitations)\n",
    "dataprotection_citations_sorted_df = get_descending_sorted_frame_of_citations(dataprotectioncitations)\n",
    "\n",
    "# Add uncited cases\n",
    "# 1. Public Health\n",
    "publichealth_newrows = []\n",
    "for item in list(uncited_publichealth_cases):\n",
    "    publichealth_newrows.append({'target' : item, 'citations' : 0})\n",
    "ph_toadd = pd.DataFrame(publichealth_newrows)\n",
    "# 2. Social Policy\n",
    "socialpolicy_newrows = []\n",
    "for item in list(uncited_socialpolicy_cases):\n",
    "    socialpolicy_newrows.append({'target' : item, 'citations' : 0})\n",
    "sp_toadd = pd.DataFrame(socialpolicy_newrows)\n",
    "# 3. Data Protection\n",
    "dataprotection_newrows = []\n",
    "for item in list(uncited_dataprotection_cases):\n",
    "    dataprotection_newrows.append({'target' : item, 'citations' : 0})\n",
    "dp_toadd = pd.DataFrame(dataprotection_newrows)\n",
    "    \n",
    "publichealth_citations_sorted_df = publichealth_citations_sorted_df.append(ph_toadd, ignore_index=True, sort=False)\n",
    "socialpolicy_citations_sorted_df = socialpolicy_citations_sorted_df.append(sp_toadd, ignore_index=True, sort=False)\n",
    "dataprotection_citations_sorted_df = dataprotection_citations_sorted_df.append(dp_toadd, ignore_index=True, sort=False)\n",
    "\n",
    "#print(len(publichealth_citations_sorted_df['target']))\n",
    "#print(len(socialpolicy_citations_sorted_df['target']))\n",
    "#print(len(dataprotection_citations_sorted_df['target']))\n",
    "\n",
    "#print(publichealth_citations_sorted_df.tail(10))\n",
    "#print(socialpolicy_citations_sorted_df.tail(10))\n",
    "#print(dataprotection_citations_sorted_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Now find the top n cited cases in each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public Health:\n",
      "-------------\n",
      "        target  citations\n",
      "0  62003CJ0453         32\n",
      "1  62004CJ0372         24\n",
      "2  61988CJ0070         12\n",
      "\n",
      "Social Policy:\n",
      "--------------\n",
      "        target  citations\n",
      "0  61990CJ0006         43\n",
      "1  61984CJ0152         40\n",
      "2  62006CJ0268         40\n",
      "\n",
      "Data Protection:\n",
      "---------------\n",
      "        target  citations\n",
      "0  62000CJ0465         17\n",
      "1  62009CJ0092         16\n",
      "2  62001CJ0101         15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to get the top n cited cases\n",
    "def find_top_n_cited_cases(cases_dataframe, n):\n",
    "    return cases_dataframe.head(n)\n",
    "\n",
    "print(\"Public Health:\")\n",
    "print(\"-------------\")\n",
    "print(find_top_n_cited_cases(publichealth_citations_sorted_df,3))\n",
    "print()\n",
    "print(\"Social Policy:\")\n",
    "print(\"--------------\")\n",
    "print(find_top_n_cited_cases(socialpolicy_citations_sorted_df,3))\n",
    "print()\n",
    "print(\"Data Protection:\")\n",
    "print(\"---------------\")\n",
    "print(find_top_n_cited_cases(dataprotection_citations_sorted_df,3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Identify the bottom 3 cited cases in each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public Health:\n",
      "-------------\n",
      "          target  citations\n",
      "178  62016CO0663          0\n",
      "179  62015CJ0138          0\n",
      "180  62011CJ0520          0\n",
      "\n",
      "Social Policy:\n",
      "--------------\n",
      "          target  citations\n",
      "704  61999CJ0026          0\n",
      "705  61989CJ0051          0\n",
      "706  61996CJ0106          0\n",
      "\n",
      "Data Protection:\n",
      "---------------\n",
      "         target  citations\n",
      "39  62015CJ0536          0\n",
      "40  62013CO0683          0\n",
      "41  62015CJ0398          0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to get the top n cited cases\n",
    "def find_bottom_n_cited_cases(cases_dataframe, n):\n",
    "    return cases_dataframe.tail(n)\n",
    "\n",
    "print(\"Public Health:\")\n",
    "print(\"-------------\")\n",
    "print(find_bottom_n_cited_cases(publichealth_citations_sorted_df,3))\n",
    "print()\n",
    "print(\"Social Policy:\")\n",
    "print(\"--------------\")\n",
    "print(find_bottom_n_cited_cases(socialpolicy_citations_sorted_df,3))\n",
    "print()\n",
    "print(\"Data Protection:\")\n",
    "print(\"---------------\")\n",
    "print(find_bottom_n_cited_cases(dataprotection_citations_sorted_df,3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Try binning the cases into quantiles (according to their number of citations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7a. First compute the bins based on the citation count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public Health:\n",
      "-------------\n",
      "      citations\n",
      "0.00        0.0\n",
      "0.10        0.0\n",
      "0.25        0.0\n",
      "0.50        1.0\n",
      "0.75        2.0\n",
      "0.90        5.0\n",
      "1.00       32.0\n",
      "\n",
      "Social Policy:\n",
      "--------------\n",
      "      citations\n",
      "0.00        0.0\n",
      "0.10        0.0\n",
      "0.25        1.0\n",
      "0.50        2.0\n",
      "0.75        5.0\n",
      "0.90        9.0\n",
      "1.00       43.0\n",
      "\n",
      "Data Protection:\n",
      "---------------\n",
      "      citations\n",
      "0.00       0.00\n",
      "0.10       0.00\n",
      "0.25       1.00\n",
      "0.50       2.50\n",
      "0.75       5.75\n",
      "0.90      10.90\n",
      "1.00      17.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to find the (.1, .25, .5, .75) quantiles for the citation numbers\n",
    "def find_citation_quantiles(cases_dataframe):\n",
    "    return cases_dataframe.quantile([0, .1, .25, .5, .75, .9, 1], axis = 0) \n",
    "\n",
    "# Function to sort and return a frame of cases with their number of citations\n",
    "def get_descending_sorted_frame_of_citations(cases_dataframe):\n",
    "    return cases_dataframe.groupby('target')['source'].count().reset_index(name='citations').sort_values('citations',ascending=False)\n",
    "\n",
    "publichealth_citation_quantiles = find_citation_quantiles(publichealth_citations_sorted_df)\n",
    "socialpolicy_citation_quantiles = find_citation_quantiles(socialpolicy_citations_sorted_df)\n",
    "dataprotection_citation_quantiles = find_citation_quantiles(dataprotection_citations_sorted_df)\n",
    "\n",
    "print(\"Public Health:\")\n",
    "print(\"-------------\")\n",
    "print(publichealth_citation_quantiles)\n",
    "print()\n",
    "print(\"Social Policy:\")\n",
    "print(\"--------------\")\n",
    "print(socialpolicy_citation_quantiles)\n",
    "print()\n",
    "print(\"Data Protection:\")\n",
    "print(\"---------------\")\n",
    "print(dataprotection_citation_quantiles)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7b. populate the bins with cases (actually do the sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "\n",
    "def get_quantile_pairs(quantile_range):\n",
    "    if len(quantile_range) < 2:\n",
    "        if len(quantile_range) == 1:\n",
    "            quantile_range.insert(0,quantile_range[0])\n",
    "            return quantile_range\n",
    "        else:\n",
    "            return quantile_range\n",
    "    else:\n",
    "        result = []\n",
    "        index = len(quantile_range)-1\n",
    "        done = False\n",
    "        while not done:\n",
    "            current_quantile_pair = []\n",
    "            current_quantile_pair.append(quantile_range[index-1])\n",
    "            current_quantile_pair.append(quantile_range[index])\n",
    "            result.append(current_quantile_pair)\n",
    "            index -= 1\n",
    "            if index == 0:\n",
    "                done = True\n",
    "        return result\n",
    "            \n",
    "def randomly_sample_case(sourcecases_df, lowerbound, upperbound):\n",
    "    index_range = sourcecases_df.index[sourcecases_df['citations'].between(lowerbound, upperbound, inclusive=True)].tolist()\n",
    "    done = False\n",
    "    index = 0\n",
    "    while not done:\n",
    "        index = random.randint(index_range[0],index_range[len(index_range)-1]+1)   \n",
    "        try:\n",
    "            row = sourcecases_df.loc[ index , : ]\n",
    "            done = True                \n",
    "        except Exception as e:\n",
    "            done = False\n",
    "    return index\n",
    "    \n",
    "def pick_cases(sourcecases_df, citation_quantiles, sample_size, quantile_range, topic):\n",
    "    quantile_range_pairs = get_quantile_pairs(quantile_range)\n",
    "    sample = []\n",
    "    for quantile_pair in quantile_range_pairs:\n",
    "        current_bin_sample = []\n",
    "        current_bin_rows = []\n",
    "        lowerbound = citation_quantiles['citations'][quantile_pair[0]]\n",
    "        upperbound = citation_quantiles['citations'][quantile_pair[1]]\n",
    "        while len(current_bin_sample) < sample_size:\n",
    "            random_index = randomly_sample_case(sourcecases_df, lowerbound, upperbound)\n",
    "            random_row = sourcecases_df.loc[ random_index , : ]\n",
    "            if (random_row['citations'] >= lowerbound and random_row['citations'] <= upperbound):\n",
    "                current_bin_sample.append([random_row['target'],random_row['citations']])\n",
    "                current_bin_sample = [list(i) for i in set(map(tuple, current_bin_sample))]\n",
    "        for item in current_bin_sample:\n",
    "            current_bin_row = []\n",
    "            current_bin_row.append(quantile_pair[1])\n",
    "            current_bin_row.append(item[0])\n",
    "            current_bin_row.append(item[1])\n",
    "            current_bin_row.append(topic)\n",
    "            current_bin_rows.append(current_bin_row)\n",
    "            sample.extend(current_bin_rows)\n",
    "    return sample\n",
    "            \n",
    "sample_cases = []\n",
    "\n",
    "sample_cases.extend(pick_cases(publichealth_citations_sorted_df, publichealth_citation_quantiles, 3, [0, .1, .25, .5, .75, .9, 1], 'public health'))\n",
    "sample_cases.extend(pick_cases(socialpolicy_citations_sorted_df, socialpolicy_citation_quantiles, 3, [0, .1, .25, .5, .75, .9, 1], 'social policy'))\n",
    "sample_cases.extend(pick_cases(dataprotection_citations_sorted_df, dataprotection_citation_quantiles, 3, [0, .1, .25, .5, .75, .9, 1], 'data protection'))\n",
    "sample_cases = [list(i) for i in set(map(tuple, sample_cases))]\n",
    "sample_cases.insert(0, ['quantile','source','citations','topic'])\n",
    "\n",
    "with open('../inputdata/sampled_cases.csv', 'w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=',')\n",
    "    writer.writerows(sample_cases)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
